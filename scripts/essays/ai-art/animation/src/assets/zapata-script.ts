export const zapataScript =
  "I am shocked that I have to say the things I am about to say. To have to earnestly grapple with Artificial Intelligences that make art, is a topic so fantastical, so absurdly science fiction, that I sometimes have difficulty taking it seriously. Unfortunately, I must take it seriously. Art AIs are here and I have found the lugubrious shadows they are casting on the artistic discourse and the minds of students difficult to ignore.  I have structured this essay as a series of counterarguments to a few of the most common rejoinders around Ai art. After that, I plan to lash you to a post and flog you publicly for your lack of resistance. That should, I hope, capture the scope of the absurdity at play here. I want to be clear up front that the coming arguments are not about whether “AI art” is “art” or not. I have no problem saying it is art- that just doesn’t amount to much within the substance of this argument. It goes without saying that human beings can express themselves with absolutely anything, and so long as there is expression involved, one will probably experience their work as art and feel themself to be an artist. But the forthcoming arguments aren’t about that point–they’re about the flawed, unethical, and deceptive environment around AI systems. One that I will argue is poised and promises to take things in a very unartistic direction. It’s not hard to imagine an ethical and consent-based generative AI image system, and that only makes it all the more galling that the ones being released now are emphatically not.   I also want to say that I, as a person of this world and time, am as morbidly curious as to what these systems can create as anyone else, and I am certain I will be deeply moved by examples of AI art in the future. However, the interesting possibilities in AI art do not mean that the horrendous oversights and anti-humanist values of its current systems are above reproach.  I must admit I will be engaging in some fortune-telling in this discussion, but considering the subject matter, I think that is inevitable, necessary, and desirable. Most of us would have called the current state of these systems a fantastical impossibility just ten years ago, and they might not have snuck up on us and disarmed us so easily if we had been willing to project a little further into the future. I have heard arguments that try to end this whole discussion before it starts- they mainly take the shape of technical assertions that these text-to-image systems cannot get better, based on the nature of their design, and we are already seeing their finished form. I am not a machine learning expert, programmer, or software engineer, but I must say I find that hard to believe given that they have already improved since previous inferior iterations. I want to make clear, however, that even if you don’t extrapolate into the future, and contend only with the current state of the art- the way these AIs are being trained, released, used, and marketed right now in the present, is already grounds for serious concern. If these AI systems are allowed to propagate, unchecked, in the way that they have thus far, a dangerous precedent will be set, revealing that ";
